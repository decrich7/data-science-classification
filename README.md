# Модель классификации документов по их адресатам

## В 1 блоке я занялся предобработкой и разведочным анализом данных для корректного обучения модели Классификации
# Проделанная работа:
1. Удалил не нужные атрибуты которые не влияют на точность и процесс ML
2. Разбил сложные атрибуты на несколько, например я отделил автора и его место работы, а также дату и исходный номер
3. В будущем планируется разбиение на словари данных, выявление ключевых слов, это повысит точность и скорость работы модели


***

**По итогам этого блока я создал Dataframe с помощью Pandas, очистил его и подготовил его к последующему обучению модели**
### Так выглядит предобработаный  Dataframe:
![image](https://user-images.githubusercontent.com/55853487/155879725-82a40f0d-d672-42ba-8c86-0373be20f7a8.png)

## В 2 блоке я занялся обучением Модели классификации и визуализацией данных
В качестве модели классификации я выбрал алгоритм **Случайны лес**

Почему был выбран RandomForestClassifier:
1. Алгоритм случайного леса не является предвзятым, поскольку существует несколько деревьев, и каждое дерево обучается на подмножестве данных.
2. Алгоритм случайного леса хорошо работает, c категориальными признаками.
3. Этот алгоритм очень стабилен. Даже если новая точка данных введена в набор данных, общий алгоритм не сильно пострадает.

***

Исходный Dataframe я разделил на тестовую и тренировочную выборку

Для непосредственного обучения модели нужна тренировочная выборка, а для для оценки качества модели используется тестовая (контрольная) выборка

    Я использовал соотношение 75% - для обучающей и 25% для тестовой

Для этого разделения я использовал _sklearn.model_selection_ и его _модуль train_test_split_

![image](https://user-images.githubusercontent.com/55853487/155880257-54f49f23-dce2-412c-abf6-839eb19dd8ff.png)

**Также я визуализировал данные чтобы понять какие атрибуты являются самыми важными для обучения**

Здесь показана круговая диаграмма, по количеству отправленных писем от авторов ТОП-5:

![image](https://user-images.githubusercontent.com/55853487/155880433-774a4d7e-42dc-48eb-92c1-91660bda37e3.png)

Тут можно посмотреть отношение писем от разных организаций

![image](https://user-images.githubusercontent.com/55853487/155880480-59a67d78-05f7-467b-9960-b4a30e6ef127.png)

На этой столбиковой диаграмме можно узнать какие адресаты самые популярные

![image](https://user-images.githubusercontent.com/55853487/155880593-17a7e2bc-c69a-431f-858d-7dc40bd11d92.png)

**Для визуализации я использовал matplotlib.pyplot, pyplot позволяет удобно строить множество видов графиков**

самым частым адресатом стал "Глушко Д.Е." и "Уразов Р.Н.", а наиболее большое количество писем из организаций - МИН ОБР РФ

Исходя из полученных данных видно что важными атрибутами являются "Организация" и "Автор"

***
В 3 блоке я обучил модель и сравнил ее результаты с другими, также я подобрал подходящие фичи

Для преобразования строк в числовой массив, я использую CountVectorizer

Для каждого обучающего текста CountVectorizer учитывает частоту каждого словаря в обучающем тексте


***
Я использовал такие модели как xgb, GradientBoostingClassifier, SVC, DecisionTreeClassifier, RandomForestClassifier

***
## XGB

![image](https://user-images.githubusercontent.com/55853487/155882297-837d8852-ff40-4f58-9bba-c6fa1a3aa798.png)

## GradientBoostingClassifier

![image](https://user-images.githubusercontent.com/55853487/155882321-7bff8057-a17f-48f3-a5e7-64711007e922.png)

## SVC

![image](https://user-images.githubusercontent.com/55853487/155882374-baa408ea-0831-4be5-b974-580ee9696f22.png)

## DecisionTreeClassifier

![image](https://user-images.githubusercontent.com/55853487/155882382-68d399dd-7207-4988-990b-25d5343bb171.png)

## RandomForestClassifier

![image](https://user-images.githubusercontent.com/55853487/155882402-4929559c-4da5-40b7-b945-e7769a2eb236.png)


При добавлении признаков - "Организация", "Краткое содержание" и "Исходный номер" -  точность модели выросла на ~ 13%

При добавлении этих признаков в остальные алгоритмы, у дерева решений точность выросла до ~ 61%, а у опорных векторов упала до 36 %

Но Лидирующем алгоритмом остается случайный лес с точностью около 70%

Я сделал ручную проверку, и она выявила довольно высокую точность модели `RandomForestClassifier`

![image](https://user-images.githubusercontent.com/55853487/155880967-11350645-42e9-4c40-85df-5a7c464c6c27.png)

## В 4 блоке я разработал бота, поддерживающего естественный язык и распознающий адресата 

В боте есть команды, которые отвечают за определенный функционал:

`Чтобы определить адресата по описанию входного документа - %determine_addres`

`Чтобы узнать справку по командам - %help`

`Чтобы определить адресата по описанию входного документа на естественном языке - %determine_addres_natural_lang`

`Выбрать одного или несколько наиболее вероятных адресатов - %maybe`

**При команде %determine_addres бот запрашивает краткое описание документа и возвращает предположительного адресата**

![image](https://user-images.githubusercontent.com/55853487/155881279-7defc829-53c8-4e8b-a000-371fced21c58.png)

**Команда %help выдает полный список команд**

**Команда %determine_addres_natural_lang позволяет понимать естественный язык и также возвращает предположительного адресата**

**Команда %maybe выводит матрицу с наиболее вероятными адресатами**

## В 5 Блоке я разработал API интерфейс

**Разработка API велась при помощи Flask, API дает возможность  подключить разработанный программный продукт в качестве модуля к системе электронного документооборота.**

Для того чтобы им воспользоваться, требуется передать в адресную строку следующие аргументы - `prim, summary, ather, orig_date, date_reg, num_doc, num_pp`

***

В качестве результата возвращаться аналогичная структура с заполненным значением атрибута Адресат

![image](https://user-images.githubusercontent.com/55853487/155881761-67a2c7ba-5025-413e-8b95-122c8bc13e6d.png)

Пример запроса - `https://5000-cs-534459886760-default.cs-europe-west4-bhnf.cloudshell.dev/get-addressee/?summary=Вх - О возможности использования сетевого издания "Информационный ресурс СПАРК" в работе Союза?num_pp=1&ather=Антонова С.В. (АО «Интерфакс»)&num_doc=208-40908.04.2019&orig_date=WSR/1-838/2019`

Сервер возвращает ответ в таком виде:

`{`

    `"num_pp": null,`

    `"num_doc": "208-40908.04.2019",`

    `"date_reg": null,`

    `"orig_date": "WSR/1-838/2019",`

    `"ather": "\u0423\u0440\u0430\u0437\u043e\u0432 \u0420.\u041d.",`

    `"summary": "\u0412\u0445 - \u041e \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0441\u0435\u0442\u0435\u0432\u043e\u0433\u043e \u0438\u0437\u0434\u0430\u043d\u0438\u044f \"\u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u0440\u0435\u0441\u0443\u0440\u0441 \u0421\u041f\u0410\u0420\u041a\" \u0432 \u0440\u0430\u0431\u043e\u0442\u0435 \u0421\u043e\u044e\u0437\u0430?num_pp=1",`

    `"prim": null`

`}`

Слова Кодируются в кодировке `UTF-8`

## Языком проекта является Python

***

Используемые сервисы для разработки:
1. Google Colab
2. Google Cloud

Основные библиотеки и фреймворки:
1. Sklearn
2. Numpy
3. Matplotlib
4. Pandas
